# React Native - Cold Start Handling Guide

## Backend Status

**âœ… Backend Optimization:** Completed with lazy loading
- Container startup: 30-40s â†’ 10-15s (60-70% faster)
- First RAG query: 10-20s (one-time ML model load)
- Subsequent queries: <2s (normal speed)

**ðŸŽ¯ Goal:** Handle the first chat message gracefully from React Native app side

---

## Problem 1: Request Timeouts on First Chat Message

**Issue:** First chat message can take 10-20 seconds while ML model loads, causing timeout errors if app timeout is too short.

**Solution:**
- Use **different timeout values** for different endpoint types
- Health/Auth endpoints: 5 seconds (fast operations)
- Chat/RAG endpoints: 30 seconds (handles model loading)
- Implement timeout handling in HTTP client (Axios/Fetch)

---

## Problem 2: Poor User Experience During Long Wait

**Issue:** User sees generic "Loading..." for 10-20 seconds with no context, causing confusion or app abandonment.

**Solution:**
- Show **progressive loading messages** that update during wait:
  - 0-5s: "Initializing AI assistant..."
  - 5-12s: "Loading financial knowledge base..."
  - 12-20s: "Almost ready..."
- Display **informative message**: "First message may take up to 20 seconds"
- Subsequent messages: Simple "Thinking..." (fast response expected)

---

## Problem 3: No Retry Mechanism for Failed Requests

**Issue:** Network hiccups or 502 errors cause permanent failure without recovery option.

**Solution:**
- Implement **automatic retry with exponential backoff**:
  - First retry: 2 seconds delay
  - Second retry: 4 seconds delay
  - Third retry: 8 seconds delay
- Only retry on server errors (5xx) and timeouts
- Don't retry on client errors (4xx - auth, validation)
- Show **retry button** to user for manual retry

---

## Problem 4: Unexpected 502 Bad Gateway Errors

**Issue:** Backend container might still be initializing or model loading causes timeout at Nginx level.

**Solution:**
- Handle **502 errors gracefully** with user-friendly message
- Display: "AI service is temporarily unavailable. Please retry."
- Offer **automatic retry** after 3-5 seconds
- Log 502 occurrences for monitoring

---

## Problem 5: No Context for First-Time Users

**Issue:** Users don't understand why first message is slower than subsequent ones.

**Solution:**
- Show **welcome screen** before chat with "Start Conversation" button
- Display informative note: "ðŸ’¡ First message takes longer as we load your personalized financial knowledge base. Subsequent messages will be much faster!"
- Optional: **Pre-warm** the service when user clicks "Start" (sends warmup request before showing chat interface)

---

## Problem 6: Network Connection Issues

**Issue:** App doesn't check network status before sending requests, causing confusing errors.

**Solution:**
- Check **network connectivity** before API calls
- Show clear message: "No internet connection. Please check your network."
- Handle **poor network** scenarios (3G/slow connection) with appropriate timeouts
- Detect network changes and notify user

---

## Problem 7: Timeout Errors Look Like App Bugs

**Issue:** Generic timeout errors make it seem like the app is broken rather than temporary delay.

**Solution:**
- Differentiate between **first message timeout** and normal timeout
- First message timeout: "Initial setup is taking longer than expected. This is normal on first use. Retry?"
- Normal timeout: "Request timed out. Please try again."
- Show **retry button** prominently
- Track first message flag to provide context-aware messages

---

## Problem 8: Auth Token Expiry During Long Wait

**Issue:** If first message takes 20s and token is close to expiry, it might expire mid-request.

**Solution:**
- Handle **403 auth errors** specifically (don't retry)
- Show: "Session expired. Please login again."
- Redirect to login screen
- Refresh token before long operations if possible

---

## Implementation Summary

### Required App Changes:

**1. HTTP Client Configuration:**
- Two timeout configurations: 5s (normal) and 30s (chat)
- Error interceptors for 502, timeout, auth errors
- Automatic retry mechanism with backoff

**2. UI/UX Improvements:**
- Progressive loading messages (3 stages)
- First message warning text
- Loading indicator with context
- Error dialogs with retry option

**3. State Management:**
- Track `isFirstMessage` flag
- Reset flag after successful first chat
- Monitor network connectivity
- Handle background/foreground transitions

**4. Error Handling:**
- Timeout: Show retry with explanation
- 502: Show "service unavailable" with retry
- 403: Redirect to login
- Network: Show connectivity message

**5. Optional Optimizations:**
- Pre-warming: Send warmup request on chat screen load
- Welcome screen: Initialize before chat starts
- Analytics: Track first message performance
- Cache warmed-up state per session

---

## Best Practices

### âœ… DO:
1. Use 30-second timeout for chat endpoints
2. Show progressive loading states with updates
3. Explain to users why first message is slower
4. Implement retry logic for 502/timeout errors
5. Check network connectivity before requests
6. Pre-warm service when user opens chat screen
7. Provide clear, actionable error messages

### âŒ DON'T:
1. Use same 5s timeout for all endpoints
2. Show generic "Loading..." for 20 seconds
3. Fail silently without user feedback
4. Retry on auth errors (403/401)
5. Assume connection is always available
6. Hide error details from user
7. Make users wait without context

---

## Testing Checklist

Test these scenarios in your React Native app:

- âœ… First message after fresh install (expect 10-20s)
- âœ… Second and subsequent messages (expect <2s)
- âœ… Timeout handling (turn off network mid-request)
- âœ… 502 error recovery (restart backend during test)
- âœ… Retry mechanism (verify exponential backoff)
- âœ… No internet connection (airplane mode)
- âœ… Slow network (enable 3G throttling)
- âœ… Background/foreground switch during request
- âœ… App restart (verify first message flag resets)
- âœ… Token expiry during long wait

---

## Performance Expectations

| Scenario | Expected Time | User Experience |
|----------|---------------|-----------------|
| Container startup | 10-15s | N/A (happens before user access) |
| First chat message | 10-20s | Progressive loading with context |
| Subsequent messages | <2s | Standard "Thinking..." loader |
| Health check | <1s | Instant response |
| Auth operations | <2s | Standard loader |

---

## Summary

**Backend:** Optimized with lazy loading âœ…

**React Native App Must:**
1. Use 30s timeout for chat endpoints
2. Show progressive loading messages
3. Warn users about first message delay
4. Implement retry logic for failures
5. Handle errors gracefully with clear messages
6. Optionally pre-warm service on screen load

This ensures smooth UX even during the one-time 10-20s model loading! ðŸš€
